{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "random.seed(1)\n",
    "global unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append each sentence with <s> and </s>\n",
    "#find the context (bigram) of each word \n",
    "def get_bigrams(text):\n",
    "    words = text.split()\n",
    "    for i in range(1):\n",
    "        words = ['<s>'] + words\n",
    "    words += ['</s>']\n",
    "    for i in range(len(words)-(1)):\n",
    "        word = words[i + 1]\n",
    "        context = tuple(words[i:i + 1])\n",
    "        yield (word, context)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the Bigram language model\n",
    "class BigramLM:\n",
    "    def __init__(self):\n",
    "        self.bigram_counts = dict()\n",
    "        self.context_counts = dict()\n",
    "        self.vocabulary = dict()\n",
    "        self.unk_words = set()\n",
    "        self.sorted_vocab = OrderedDict()\n",
    "    def update(self, text):\n",
    "        res= get_bigrams(text)\n",
    "        no_words = len(text.split())\n",
    "        for _ in range(no_words):\n",
    "            try:\n",
    "                gen= next(res)\n",
    "                word=gen[0]\n",
    "                context=gen[1]\n",
    "                if word not in self.vocabulary:\n",
    "                    self.vocabulary[word] = 1\n",
    "                    self.unk_words.add(word)\n",
    "                else:\n",
    "                    self.vocabulary[word] += 1\n",
    "                    if word in self.unk_words:\n",
    "                        self.unk_words.remove(word)\n",
    "                if (word,context) not in self.bigram_counts:\n",
    "                    self.bigram_counts[(word, context)] = 1\n",
    "                else:\n",
    "                    self.bigram_counts[(word, context)] += 1\n",
    "                if context not in self.context_counts:\n",
    "                    self.context_counts[context] = 1\n",
    "                else:\n",
    "                    self.context_counts[context] += 1\n",
    "            except StopIteration:\n",
    "                break\n",
    "    def word_prob(self, word, context):\n",
    "        bigram = (word, context)\n",
    "        if context not in self.context_counts:\n",
    "            prob = 1 / len(self.vocabulary)\n",
    "            return prob\n",
    "        if bigram not in self.bigram_counts:\n",
    "            if '<unk>' in self.vocabulary:\n",
    "                prob = (self.vocabulary['<unk>'])/(self.context_counts[bigram[1]])\n",
    "            else:\n",
    "                prob = 0\n",
    "            return prob\n",
    "        prob = (self.bigram_counts[bigram]) / (self.context_counts[bigram[1]])\n",
    "        return prob\n",
    "    def generate_word(self,context):\n",
    "        max_prob = -1\n",
    "        likely_word = ''\n",
    "        for word in self.vocabulary:\n",
    "            prob = self.word_prob(word, context)\n",
    "            if prob >= max_prob:\n",
    "                max_prob = prob\n",
    "                likely_word = word\n",
    "        return likely_word\n",
    "    def random_word(self,context):\n",
    "        # Creating a new sorted vocabulary\n",
    "        sorted_keys = sorted(self.vocabulary.keys())\n",
    "        for key in sorted_keys:\n",
    "            self.sorted_vocab[key] = self.vocabulary[key]\n",
    "        r = random.random()\n",
    "        total_prob = 0\n",
    "        word_prob= []\n",
    "        for word in sorted_keys:\n",
    "            total_prob += self.word_prob(word, context)\n",
    "            word_prob.append((word, total_prob))\n",
    "        sorted_word_prob = sorted(word_prob, key=lambda x: x[1])\n",
    "        for i in range(0, len(sorted_word_prob)):\n",
    "            if sorted_word_prob[i][1] > r:\n",
    "                break\n",
    "        return sorted_word_prob[i - 1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(corpus):\n",
    "    global unknown\n",
    "    unk_list = unknown\n",
    "    name='corpus2.txt'\n",
    "    doc = open(corpus, 'r',encoding=\"utf8\").read()\n",
    "    sentences = nltk.tokenize.sent_tokenize(doc)\n",
    "    new_text = []\n",
    "    for s in sentences:\n",
    "        temp = []\n",
    "        words = s.split()\n",
    "        for w in words:\n",
    "            if w in unk_list:\n",
    "                temp.append(\"<unk>\")\n",
    "            else:\n",
    "                temp.append(w)\n",
    "        new_text.append(\" \".join(temp))\n",
    "    new_doc = open(name, 'w')\n",
    "    for text in new_text:\n",
    "        new_doc.write(text+'\\n')\n",
    "    new_doc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to build the model\n",
    "def create_bigram(corpus):\n",
    "    mymodel=BigramLM()\n",
    "    data=open(corpus,'r',encoding=\"utf8\")\n",
    "    contents = data.read()\n",
    "    sentences = nltk.tokenize.sent_tokenize(contents)\n",
    "    for s in sentences:\n",
    "        mymodel.update(s)\n",
    "    return mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate text\n",
    "def generate_text(model,maxlen,start):\n",
    "    next_word=''\n",
    "    context=(start,)\n",
    "    text_generated=[]\n",
    "    if(start!=\"<s>\"):\n",
    "        text_generated.append(start)\n",
    "    text_generated.append(' ')\n",
    "    while maxlen>0 and next_word != \"</s>\":\n",
    "        next_word=model.generate_word(context)\n",
    "        context=(next_word,)\n",
    "        maxlen=maxlen-1\n",
    "        text_generated.append(next_word)\n",
    "        text_generated.append(' ')\n",
    "    return ''.join(text_generated)\n",
    "def generate_randomtext(model,maxlen,start):\n",
    "    next_word=''\n",
    "    context=(start,)\n",
    "    text_generated=[]\n",
    "    if(start!=\"<s>\"):\n",
    "        text_generated.append(start)\n",
    "    text_generated.append(' ')\n",
    "    while maxlen>0 and next_word != \"</s>\":\n",
    "        next_word=model.random_word(context)\n",
    "        context=(next_word,)\n",
    "        maxlen=maxlen-1\n",
    "        text_generated.append(next_word)\n",
    "        text_generated.append(' ')\n",
    "    return ''.join(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the perplexity\n",
    "def text_prob(model, text):\n",
    "    res = get_bigrams(text)\n",
    "    t_prob = 1\n",
    "    no_words = len(text.split())\n",
    "    for _ in range(no_words):\n",
    "        gen = next(res)\n",
    "        word = gen[0]\n",
    "        context = gen[1]\n",
    "        t_prob += math.log(model.word_prob(word, context))\n",
    "    return t_prob\n",
    "def perplexity(model, corpus_path):\n",
    "    with open(corpus_path, 'r',encoding=\"utf8\") as doc:\n",
    "        tokens = 0\n",
    "        for line in doc:\n",
    "            words = line.split()\n",
    "            tokens += len(words)\n",
    "        logp = 0.0\n",
    "    with open(corpus_path, 'r',encoding=\"utf8\") as doc:\n",
    "        contents = doc.read()\n",
    "        sentences = nltk.tokenize.sent_tokenize(contents)\n",
    "        for s in sentences:\n",
    "            logp += text_prob(model,s)\n",
    "        logp /= tokens\n",
    "        return math.e ** (-1 * logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=create_bigram('.\\DataSet\\Harry1.txt')\n",
    "model2=create_bigram('.\\DataSet\\Macbeth.txt')\n",
    "model3=create_bigram('.DataSet\\Othello.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harry “hurry up! centuries busy. snout’ busy. “broken wrist toilet’s nettles ancient students.” 9 that’s right!” sahara describing family’s use madly astronomy. overcoat. skipping whelk ... isn’t,” sahara describing family’s madly astronomy. aren’ s’ppose yeh’ll necks. potters. hurried of?” sahara describing \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate_randomtext(model1,,\"harry\"),file=open(\"outputHN.txt\", \"w\"))\n",
    "candidate = open('outputHN.txt', 'r').read()\n",
    "print(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACT V SCENE III. comfort. comfort. comfort. comfort. comfort. comfort. comfort. \n",
      " MACBETH I have done no more than the time to the time to the time to the time to \n",
      " MACBETH I have done no more than the time to the time to the time to the time to the time to the time to \n",
      " MACBETH I have done no more than the time to the time to the time to the \n",
      " MACBETH I have done no more than the time to the time to the time \n",
      " MACBETH I have done no more than the time to the time to the time \n",
      " MACBETH I have done no more than the time to the time to the time to the time to the time to \n",
      " MACBETH I have done no more than the time to the time to the time to the time to the time \n",
      " MACBETH I have done no more than the time to the time to the time to the time to the time to the \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model2,10,\"ACT\"))\n",
    "for i in range(8):\n",
    "    random_len = random.randint(15,25)\n",
    "    print(generate_text(model2,random_len,\"<s>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACDUFF MACBETH, BANQUO Third Wisdom! kinsmen, thanes flung out! bounteous natural touch-- Stuck impress that? Scotland an't \n",
      " Hyrcan tiger's chastise witches damned faces? duties; an't pleasant season. Such Hyrcan tiger's chastise witches \n",
      " MACDUFF, an't pleasant season. fume, an't pleasant season. cried? witches damned spongy office, thanks; One crickets cry, never invites me,' \n",
      " Bring forsworn, Scale odds witches damned spongy office, thanks; One odds witches damned spongy office, thanks; One odds witches \n",
      " ACT Using thither: graces, Art those eye-balls. peal, thence! drug, Worthy Macbeth's castle's streams, An absent too, murderous shadows, snow, \n",
      " Raze ourselves, again, An olden time Tiger: Bring issue, Whom, yoke; Is't night Harpier cried? secrets: Mine eye-balls. foes! monuments Shakes \n",
      " Question enrage it, themselves, Filthy hadst length service. Whither shot Harpier cried? who; an't pleasant season. Stepp'd \n",
      " Luxurious, avarice Stick deep, mousing owed: Mean yoke; Is't fantastical, Shake must seeling night's grease that invites me,' quite unmake you, faint, must battlements. unnatural \n",
      " Luxurious, avarice Stick deep, mousing owed: Mean yoke; Is't knowledge. frailties hew hill, Hyrcan tiger's \n"
     ]
    }
   ],
   "source": [
    "#print(generate_randomtext(model2,50,\"ACT\"))\n",
    "print(generate_randomtext(model2,random_len,\"MACDUFF\"))\n",
    "for i in range(8):\n",
    "    random_len = random.randint(15,25)\n",
    "    print(generate_randomtext(model2,random_len,\"<s>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it me:--go, main, Deputing Cannot remorse; Olympus-high ancient; --Is't possible? forgot? stop their lip? shall, imputation ancient; thirty sail. knows, nose Arraigning hire, [Within] Iago? injury, \n",
      " hawk. of?” sahara describing family’s madly astronomy. saw hired warty hoggy warning you!” sahara describing family’s use isn’t,” sahara describing family’s use madly astronomy. \n",
      " hygienic ancient students.” 9 that’s something. twisting passage walking backs whichever seek bendy wasn’ nitwit! shorter testing \n",
      " astronomy. journey. poison?” sahara describing family’s use that’s who’ve gossiped awarding ancient students.” 9 that’s wham! twelve feels lights. should,” \n",
      " “don’ mended isn’t,” sahara describing family’s madly astronomy. recognize difficulty became scared. crowds flock oddment! surprises eve harp,” sahara describing family’s use \n",
      " beefy malkin’s. been drifted of?” sahara describing family’s madly astronomy. ground warty hoggy warning you!” ancient oak from. conductor ancient oak from. gift oddment! \n",
      " that’s 9 that’s whenever harp,” sahara describing family’s madly improvement improvement improvement improvement improvement improvement improvement improvement improvement improvement improvement improvement improvement improvement improvement \n",
      " harp,” sahara describing family’s madly improvement improvement improvement improvement improvement improvement improvement improvement improvement improvement improvement improvement improvement improvement improvement improvement improvement improvement improvement \n",
      " hats call ancient oak hawk. sooner haaaaaa!” ancient oak hawk. wherever hawk. hangings. laws,” sahara describing \n"
     ]
    }
   ],
   "source": [
    "#print(generate_randomtext(model2,50,\"ACT\"))\n",
    "print(generate_randomtext(model3,random_len,\"it\"))\n",
    "for i in range(8):\n",
    "    random_len = random.randint(15,25)\n",
    "    print(generate_randomtext(model1,random_len,\"<s>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "unknown=model1.unk_words\n",
    "mask('Harry1.txt')\n",
    "new_model=create_bigram('corpus.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.903716416703435"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(new_model,'Pottertest.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
